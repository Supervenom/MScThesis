
@article{church_unsolvable_1936,
	title = {An Unsolvable Problem of Elementary Number Theory},
	volume = {58},
	pages = {345--363},
	number = {2},
	journaltitle = {American Journal of Mathematics},
	author = {Church, Alonzo},
	date = {1936}
}

@inproceedings{ferrer_fioriti_probabilistic_2015,
	title = {Probabilistic Termination: Soundness, Completeness, and Compositionality},
	isbn = {978-1-4503-3300-9},
	shorttitle = {Probabilistic Termination},
	abstract = {We propose a framework to prove almost sure termination for probabilistic programs with real valued variables. It is based on ranking supermartingales, a notion analogous to ranking functions on non-probabilistic programs. The framework is proven sound and complete for a meaningful class of programs involving randomization and bounded nondeterminism. We complement this foundational insigh by a practical proof methodology, based on sound conditions that enable compositional reasoning and are amenable to a direct implementation using modern theorem provers. This is integrated in a small dependent type system, to overcome the problem that lexicographic ranking functions fail when combined with randomization. Among others, this compositional methodology enables the verification of probabilistic programs outside the complete class that admits ranking supermartingales.},
	pages = {489--501},
	booktitle = {Proc. of 42\${\textasciicircum}{\textbackslash}mathrmnd\$ {POPL}},
	publisher = {{ACM}},
	author = {Ferrer Fioriti, Luis María and Hermanns, Holger},
	date = {2015},
	keywords = {probabilistic programs, program verification, supermartingales, termination}
}

@inproceedings{bournez_proving_2005,
	title = {Proving Positive Almost-Sure Termination},
	volume = {3467},
	isbn = {978-3-540-25596-3 978-3-540-32033-3},
	series = {{LNCS}},
	abstract = {In order to extend the modeling capabilities of rewriting systems, it is rather natural to consider that the firing of rules can be subject to some probabilistic laws. Considering rewrite rules subject to probabilities leads to numerous questions about the underlying notions and results.We focus here on the problem of termination of a set of probabilistic rewrite rules. A probabilistic rewrite system is said almost surely terminating if the probability that a derivation leads to a normal form is one. Such a system is said positively almost surely terminating if furthermore the mean length of a derivation is finite. We provide several results and techniques in order to prove positive almost sure termination of a given set of probabilistic rewrite rules. All these techniques subsume classical ones for non-probabilistic systems.},
	pages = {323--337},
	booktitle = {Proc. of 16\${\textasciicircum}{\textbackslash}mathrmth\$ {RTA}},
	publisher = {Springer},
	author = {Bournez, Olivier and Garnier, Florent},
	urldate = {2018-03-09},
	date = {2005},
	langid = {english}
}

@book{norris_markov_1998,
	title = {Markov Chains},
	abstract = {Markov chains are central to the understanding of random processes. This is not only because they pervade the applications of random processes, but also because one can calculate explicitly many quantities of interest. This textbook, aimed at advanced undergraduate or {MSc} students with some background in basic probability theory, focuses on Markov chains and quickly develops a coherent and rigorous theory whilst showing also how actually to apply it. Both discrete-time and continuous-time chains are studied. A distinguishing feature is an introduction to more advanced topics such as martingales and potentials in the established context of Markov chains. There are applications to simulation, economics, optimal control, genetics, queues and many other topics, and exercises and examples drawn both from theory and practice. It will therefore be an ideal text either for elementary courses on random processes or those that are more oriented towards applications.},
	publisher = {Cambridge University Press},
	author = {Norris, J. R.},
	date = {1998},
	langid = {english},
	keywords = {Mathematics / Probability \& Statistics / General}
}

@article{xi_upper_1999,
	title = {Upper bounds for standardizations and an application},
	volume = {64},
	abstract = {{AbstractWe} present a new proof for the standardization theorem in λ-calculus, which is largely built upon a structural induction on λ-terms. We then extract some bounds for the number of β-reduction steps in the standard β-reduction sequence obtained from transforming a given β-reduction sequence, sharpening the standardization theorem. As an application, we establish a super exponential bound for the lengths of β-reduction sequences from any given simply typed λ-terms.},
	pages = {291--303},
	number = {1},
	journaltitle = {The Journal of Symbolic Logic},
	author = {Xi, Hongwei},
	date = {1999},
	langid = {english}
}

@book{barendregt_lambda_1984,
	title = {The lambda calculus: its syntax and semantics},
	shorttitle = {The lambda calculus},
	abstract = {The revised edition contains a new chapter which provides an elegant description of the semantics. The various classes of lambda calculus models are described in a uniform manner. Some didactical improvements have been made to this edition. An example of a simple model is given and then the general theory (of categorical models) is developed. Indications are given of those parts of the book which can be used to form a coherent course.},
	publisher = {North-Holland},
	author = {Barendregt, Hendrik Pieter},
	date = {1984},
	langid = {english},
	keywords = {Lambda calculus, Mathematics / Calculus, Mathematics / Logic, Mathematics / Reference}
}

@book{bremaud_markov_1999,
	title = {Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues},
	shorttitle = {Markov Chains},
	abstract = {In this book, the author begins with the elementary theory of Markov chains and very progressively brings the reader to the more advanced topics. He gives a useful review of probability that makes the book self-contained, and provides an appendix with detailed proofs of all the prerequisites from calculus, algebra, and number theory. A number of carefully chosen problems of varying difficulty are proposed at the close of each chapter, and the mathematics are slowly and carefully developed, in order to make self-study easier. The author treats the classic topics of Markov chain theory, both in discrete time and continuous time, as well as the connected topics such as finite Gibbs fields, nonhomogeneous Markov chains, discrete- time regenerative processes, Monte Carlo simulation, simulated annealing, and queuing theory. The result is an up-to-date textbook on stochastic processes. Students and researchers in operations research and electrical engineering, as well as in physics and biology, will find it very accessible and relevant.},
	publisher = {Springer-Verlag},
	author = {Bremaud, Pierre},
	date = {1999},
	langid = {english}
}

@article{zantema_strategy_2012,
	title = {Strategy Independent Reduction Lengths in Rewriting and Binary Arithmetic},
	volume = {82},
	issn = {2075-2180},
	abstract = {In this paper we give a criterion by which one can conclude that every reduction of a basic term to normal form has the same length. As a consequence, the number of steps to reach the normal form is independent of the chosen strategy. In particular this holds for {TRSs} computing addition and multiplication of natural numbers, both in unary and binary notation.},
	pages = {69--76},
	journaltitle = {Electronic Proceedings in Theoretical Computer Science},
	author = {Zantema, Hans},
	urldate = {2018-03-21},
	date = {2012},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages}
}

@article{sinot_sub-lambda-calculi_2008,
	title = {Sub-{\textbackslash}lambda-calculi, Classified},
	volume = {203},
	issn = {1571-0661},
	series = {Proc. of 4th {TERMGRAPH}},
	abstract = {When sharing is studied in the λ-calculus, some sub-calculi often pop up, for instance λI or the linear λ-calculus. In this paper, we generalise these to a large class of sub-calculi, parametrised by an arbitrary predicate on the number of occurrences of bound variables. Such a definition only makes sense when the sub-calculi are stable by β-reduction. Surprisingly, we are able to give a complete description and classification of such stable sub-calculi, in a rather algebraic way; and surprisingly again, we discover some unexpected such subcalculi. This could lead to a better understanding of the structure of the λ-calculus.},
	pages = {123--133},
	number = {1},
	journaltitle = {Electronic Notes in Theoretical Computer Science},
	author = {Sinot, François-Régis},
	date = {2008},
	keywords = {-calculus, linearity, sharing}
}

@book{terese_term_2003,
	title = {Term Rewriting Systems},
	abstract = {Term rewriting systems, which developed out of mathematical logic, consist of sequences of discrete steps where one term is replaced with another. Their many applications range from automatic theorem proving systems to computer algebra. This book begins with several examples, followed by a chapter on basic notions that provides a foundation for the rest of the work. First-order and higher-order theories are presented, with much of the latter material appearing for the first time in book form. Subjects treated include orthogonality, termination, lambda calculus and term graph rewriting. There is also a chapter detailing the required mathematical background.},
	publisher = {Cambridge University Press},
	author = {{Terese}},
	date = {2003}
}

@book{baader_term_1999,
	title = {Term Rewriting and All That},
	abstract = {This textbook offers a unified, self-contained introduction to the field of term rewriting. Baader and Nipkow cover all the basic material–abstract reduction systems, termination, confluence, completion, and combination problems–but also some important and closely connected subjects: universal algebra, unification theory, Gröbner bases, and Buchberger's algorithm. They present the main algorithms both informally and as programs in the functional language Standard {ML} (An appendix contains a quick and easy introduction to {ML}). Key chapters cover crucial algorithms such as unification and congruence closure in more depth and develop efficient Pascal programs. The book contains many examples and over 170 exercises. This is also an ideal reference book for professional researchers: results spread over many conference and journal articles are collected here in a unified notation, detailed proofs of almost all theorems are provided, and each chapter closes with a guide to the literature.},
	publisher = {Cambridge University Press},
	author = {Baader, Franz and Nipkow, Tobias},
	date = {1999}
}

@book{ash_probability_1999,
	location = {San Diego},
	edition = {Second},
	title = {Probability and Measure Theory},
	abstract = {Probability and Measure Theory, Second Edition, is a text for a graduate-level course in probability that includes essential background topics in analysis. It provides extensive coverage of conditional probability and expectation, strong laws of large numbers, martingale theory, the central limit theorem, ergodic theory, and Brownian motion.Clear, readable {styleSolutions} to many problems presented in {textSolutions} manual for {instructorsMaterial} new to the second edition on ergodic theory, Brownian motion, and convergence theorems used in {statisticsNo} knowledge of general topology required, just basic analysis and metric {spacesEfficient} organization},
	publisher = {Academic Press},
	author = {Ash, Robert B. and Doléans-Dade, Catherine A.},
	date = {1999}
}

@book{curry_combinatory_1958,
	title = {Combinatory Logic},
	publisher = {North-Holland},
	author = {Curry, Haskell Brooks and Feys, Robert},
	date = {1958},
	langid = {english}
}

@inproceedings{avanzini_probabilistic_2018,
	title = {On Probabilistic Term Rewriting},
	volume = {10818},
	isbn = {978-3-319-90685-0 978-3-319-90686-7},
	series = {{LNCS}},
	abstract = {We study the termination problem for probabilistic term rewrite systems. We prove that the interpretation method is sound and complete for a strengthening of positive almost sure termination, when abstract reduction systems and term rewrite systems are considered. Two instances of the interpretation method—polynomial and matrix interpretations—are analyzed and shown to capture interesting and nontrivial examples when automated. We capture probabilistic computation in a novel way by means of multidistribution reduction sequences, thus accounting for both the nondeterminism in the choice of the redex and the probabilism intrinsic in firing each rule.},
	pages = {132--148},
	booktitle = {Proc. of 14\${\textasciicircum}{\textbackslash}mathrmth\$ {FLOPS}},
	publisher = {Springer},
	author = {Avanzini, Martin and Dal Lago, Ugo and Yamada, Akihisa},
	urldate = {2018-05-07},
	date = {2018},
	langid = {english}
}

@book{motwani_randomized_1995,
	title = {Randomized Algorithms},
	abstract = {This text by two well-known experts in the field presents the basic concepts in the design and analysis of randomized algorithms at a level accessible to beginning graduate students, professionals and researchers.},
	publisher = {Cambridge University Press},
	author = {Motwani, Rajeev and Raghavan, Prabhakar},
	date = {1995}
}

@inproceedings{bournez_probabilistic_2002,
	title = {Probabilistic Rewrite Strategies. Applications to {ELAN}},
	volume = {2378},
	isbn = {978-3-540-45610-0},
	series = {{LNCS}},
	abstract = {Recently rule based languages focussed on the use of rewriting as a modeling tool which results in making specifications executable. To extend the modeling capabilities of rule based languages, we explore the possibility of making the rule applications subject to probabilistic choices.},
	pages = {252--266},
	booktitle = {Proc. of 13\${\textasciicircum}{\textbackslash}mathrmth\$ {RTA}},
	publisher = {Springer},
	author = {Bournez, Olivier and Kirchner, Claude},
	date = {2002}
}

@article{dal_lago_randomised_2018,
	title = {On Randomised Strategies in the {\textbackslash}lambda-Calculus (Long Version)},
	url = {Available at: http://arxiv.org/abs/1805.03934},
	abstract = {In this work we introduce randomised reduction strategies, a notion already studied in the context of abstract reduction systems, for the \${\textbackslash}textbackslashlambda\$-calculus. We develop a simple framework that allows us to prove if a probabilistic strategy is positive almost-surely normalising. Then we propose a simple example of probabilistic strategy for the \${\textbackslash}textbackslashlambda\$-calculus that has such a property and we show why it is non-trivial with respect to classical deterministic strategies such as leftmost-outermost or rightmost-innermost. We conclude studying this strategy for two classical sub-\${\textbackslash}textbackslashlambda\$-calculi, namely those in which duplication and erasure are syntactically forbidden.},
	author = {Dal Lago, Ugo and Vanoni, Gabriele},
	urldate = {2018-05-28},
	date = {2018},
	keywords = {Computer Science - Logic in Computer Science}
}

@article{mitschke_standardization_1979,
	title = {The Standardization Theorem for {\textbackslash}lambda-Calculus},
	volume = {25},
	pages = {29--31},
	number = {1},
	journaltitle = {Zeitschrift für Mathematische Logik und Grundlagen der Mathematik},
	author = {Mitschke, Gerd},
	date = {1979},
	langid = {german}
}

@book{klop_combinatory_1980,
	title = {Combinatory Reduction Systems},
	publisher = {Mathematisch Centrum},
	author = {Klop, J. W.},
	date = {1980}
}

@online{noauthor_rta_nodate,
	title = {{RTA}},
	url = {http://rewriting.loria.fr/rta/},
	urldate = {2018-08-17},
	file = {RTA:/home/supervenom/Zotero/storage/DJHBZV9Q/rta.html:text/html}
}

@online{noauthor_notitle_nodate,
	url = {https://www.mimuw.edu.pl/tlca/tlca.html},
	urldate = {2018-08-17},
	file = {:/home/supervenom/Zotero/storage/A328MQM2/tlca.html:text/html}
}

@article{backus_syntax_1959,
	title = {The syntax and semantics of the proposed international algebraic language of the Zurich {ACM}-{GAMM} Conference},
	url = {/paper/The-syntax-and-semantics-of-the-proposed-algebraic-Backus/790ea9d7f910ef2def2418b44a69b111d9f8ceec},
	abstract = {This paper gives a tutorial summary of the syntax and interpretation rules of the proposed international algebraic language put forward by the Zurich {ACM}-{GAMM} Conference, followed by a formal, complete presentation of the same information. Notations are presented for numbers, numerical variables, Boolean variables, relations, n-dimensional arrays, functi ons, operator s and algebraic expre s sions. Means are provided in the language for specifying assignment of values to. variables, conditional execution of statements, iterative proce\&lt;i;ures, formation of compound statements from sequences of statements, definition of new statements for arbitrary procedures, reuse and alteration of program segments. The proposed language is intended to provide convenient and concise means for expressing virtually all procedures of {numericaL} computation while employing relatively few syntactical rules and statement types.},
	author = {Backus, John W.},
	urldate = {2018-08-17},
	date = {1959},
	file = {Full Text PDF:/home/supervenom/Zotero/storage/FVE99LSV/Backus - 1959 - The syntax and semantics of the proposed internati.pdf:application/pdf;Snapshot:/home/supervenom/Zotero/storage/Q9QNGTDM/790ea9d7f910ef2def2418b44a69b111d9f8ceec.html:text/html}
}

@article{dal_lago_invariant_2005,
	title = {An Invariant Cost Model for the Lambda Calculus},
	abstract = {We define a new cost model for the call-by-value lambda-calculus satisfying the invariance thesis. That is, under the proposed cost model, Turing machines and the call-by-value lambda-calculus can simulate each other within a polynomial time overhead. The model only relies on combinatorial properties of usual beta-reduction, without any reference to a specific machine or evaluator. In particular, the cost of a single beta reduction is proportional to the difference between the size of the redex and the size of the reduct. In this way, the total cost of normalizing a lambda term will take into account the size of all intermediate results (as well as the number of steps to normal form).},
	journaltitle = {{arXiv}:cs/0511045},
	author = {Dal Lago, Ugo and Martini, Simone},
	date = {2005},
	keywords = {Computer Science - Computational Complexity, Computer Science - Logic in Computer Science, F.4.1},
	file = {arXiv\:cs/0511045 PDF:/home/supervenom/Zotero/storage/L5BUHRGJ/Lago e Martini - 2005 - An Invariant Cost Model for the Lambda Calculus.pdf:application/pdf;arXiv.org Snapshot:/home/supervenom/Zotero/storage/TQF38K77/0511045.html:text/html}
}

@article{de_bruijn_lambda_1972,
	title = {Lambda calculus notation with nameless dummies, a tool for automatic formula manipulation, with application to the Church-Rosser theorem},
	volume = {75},
	abstract = {In ordinary lambda calculus the occurrences of a bound variable are made recognizable by the use of one and the same (otherwise irrelevant) name at all occurrences. This convention is known to cause considerable trouble in cases of substitution. In the present paper a different notational system is developed, where occurrences of variables are indicated by integers giving the “distance” to the binding λ instead of a name attached to that λ. The system is claimed to be efficient for automatic formula manipulation as well as for metalingual discussion. As an example the most essential part of a proof of the Church-Rosser theorem is presented in this namefree calculus.},
	pages = {381--392},
	number = {5},
	journaltitle = {Indagationes Mathematicae (Proceedings)},
	author = {de Bruijn, N. G},
	date = {1972},
	file = {ScienceDirect Full Text PDF:/home/supervenom/Zotero/storage/LNMXKRMM/de Bruijn - 1972 - Lambda calculus notation with nameless dummies, a .pdf:application/pdf;ScienceDirect Snapshot:/home/supervenom/Zotero/storage/5CLST2AW/1385725872900340.html:text/html}
}

@article{rabin_probabilistic_1963,
	title = {Probabilistic automata},
	volume = {6},
	issn = {0019-9958},
	url = {http://www.sciencedirect.com/science/article/pii/S0019995863902900},
	doi = {10.1016/S0019-9958(63)90290-0},
	abstract = {Probabilistic automata (p.a.) are a generalization of finite deterministic automata. We follow the formulation of finite automata in Rabin and Scott (1959) where the automata \%plane1D;504; have two-valued output and thus can be viewed as defining the set T(\%plane1D;504;) of all tapes accepted by \%plane1D;504;. This involves no loss of generality. A p.a. is an automaton which, when in state s and when input is σ, has a probability pi(s, σ)\} of going into any state si. With any cut-point 0 ≤ λ {\textless} 1, there is associated the set T(\%plane1D;504;,λ) of tapes accepted by \%plane1D;504; with cut-point λ. Here we develop a general theory of p.a. and solve some of the basic problems. Aside from the mathematical interest in pursuing this natural generalization of finite automata, the results also bear on questions of reliability of sequential circuits. P.a. are, in general, stronger than deterministic automata (Theorem 2). By studying the way we may want to use p.a. we are led to introduce the concept of isolated cut-point. It turns out that every p.a. with isolated cut-point is equivalent to a suitable deterministic automaton (the Reduction Theorem 3). It is interesting to note that in passing from a minimal deterministic automaton to an equivalent p.a. we can sometimes save states (Section {VII}). The Reduction Theorem is applied to prove the existence of an approximate calculation procedure for a calculation problem involving products of stochastic matrices (Section {VIII}). The problem is of a new kind in that there is no a-priori bound on the number of operations (matrix multiplications) which we may have to perform and therefore classical numerical estimates of round-off errors do not apply. Actual automata (Definition 9) have the property, often existing in actual unreliable circuits, that all transition probabilities are strictly positive. Actual automata are proved to give only definite events. This points to the restrictions we may have to impose on a probabilistic sequential circuit if we want it to perform general tasks, namely, some transitions should be prohibited. Finally we treat the important problem of stability. Is the operation of a p.a. stable (unchanged) under small enough perturbations of the transition probabilities? We have an affirmative answer to this question in the case of actual automata (Theorem 11) and we discuss the problem for the general case.},
	pages = {230--245},
	number = {3},
	journaltitle = {Information and Control},
	author = {Rabin, Michael O.},
	urldate = {2018-08-20},
	date = {1963-09-01},
	file = {ScienceDirect Full Text PDF:/home/supervenom/Zotero/storage/XXGIVC9R/Rabin - 1963 - Probabilistic automata.pdf:application/pdf;ScienceDirect Snapshot:/home/supervenom/Zotero/storage/DMB7G4NM/S0019995863902900.html:text/html}
}

@article{rabin_probabilistic_1980,
	title = {Probabilistic algorithm for testing primality},
	volume = {12},
	abstract = {We present a practical probabilistic algorithm for testing large numbers of arbitrary form for primality. The algorithm has the feature that when it determines a number composite then the result is always true, but when it asserts that a number is prime there is a provably small probability of error. The algorithm was used to generate large numbers asserted to be primes of arbitrary and special forms, including very large numbers asserted to be twin primes. Theoretical foundations as well as details of implementation and experimental results are given.},
	pages = {128--138},
	number = {1},
	journaltitle = {Journal of Number Theory},
	author = {Rabin, Michael O.},
	date = {1980},
	file = {ScienceDirect Full Text PDF:/home/supervenom/Zotero/storage/GTWH6N77/Rabin - 1980 - Probabilistic algorithm for testing primality.pdf:application/pdf;ScienceDirect Snapshot:/home/supervenom/Zotero/storage/EBCHYXPR/0022314X80900840.html:text/html}
}

@inproceedings{goldreich_how_1984,
	title = {How To Construct Random Functions},
	abstract = {This paper develops a constructive theory of randomness for functions based on computational complexity. We present a deterministic polynomial-time algorithm that transforms pairs (g,r), where g is any one-way (in a very weak sense) function and r is a random k-bit string, to polynomial-time computable functions f/sub r/:1,..., 2/sup k /spl I.oarr/ 1, ..., 2/sup k/. These f/sub r/'s cannot be distinguished from random functions by any probabilistic polynomial time algorithm that asks and receives the value of a function at arguments of its choice. The result has applications in cryptography, random constructions and complexity theory.},
	eventtitle = {25th Annual Symposium on Foundations of Computer Science, 1984.},
	pages = {464--479},
	booktitle = {25th Annual Symposium on Foundations of Computer Science, 1984.},
	author = {Goldreich, O. and Goldwasser, S. and Micali, S.},
	date = {1984-10},
	keywords = {Computational complexity, Cryptography, Indexing, Polynomials, Reflection},
	file = {IEEE Xplore Abstract Record:/home/supervenom/Zotero/storage/EFGDMDNT/715949.html:text/html}
}

@inproceedings{wood_new_2014,
	title = {A New Approach to Probabilistic Programming Inference},
	abstract = {We introduce and demonstrate a new approach to inference in expressive probabilistic programming languages based on particle Markov chain Monte Carlo. Our approach is easy to implement and to paral...},
	eventtitle = {Artificial Intelligence and Statistics},
	pages = {1024--1032},
	booktitle = {Artificial Intelligence and Statistics},
	author = {Wood, Frank and Meent, Jan Willem and Mansinghka, Vikash},
	date = {2014-04-02},
	langid = {english},
	file = {Full Text PDF:/home/supervenom/Zotero/storage/S4RUK3DJ/Wood et al. - 2014 - A New Approach to Probabilistic Programming Infere.pdf:application/pdf;Snapshot:/home/supervenom/Zotero/storage/QG47TELQ/wood14.html:text/html}
}

@inproceedings{staton_semantics_2016,
	location = {New York, {NY}, {USA}},
	title = {Semantics for Probabilistic Programming: Higher-order Functions, Continuous Distributions, and Soft Constraints},
	isbn = {978-1-4503-4391-6},
	url = {http://doi.acm.org/10.1145/2933575.2935313},
	doi = {10.1145/2933575.2935313},
	series = {{LICS} '16},
	shorttitle = {Semantics for Probabilistic Programming},
	abstract = {We study the semantic foundation of expressive probabilistic programming languages, that support higher-order functions, continuous distributions, and soft constraints (such as Anglican, Church, and Venture). We define a metalanguage (an idealised version of Anglican) for probabilistic computation with the above features, develop both operational and denotational semantics, and prove soundness, adequacy, and termination. This involves measure theory, stochastic labelled transition systems, and functor categories, but admits intuitive computational readings, one of which views sampled random variables as dynamically allocated read-only variables. We apply our semantics to validate nontrivial equations underlying the correctness of certain compiler optimisations and inference algorithms such as sequential Monte Carlo simulation. The language enables defining probability distributions on higher-order functions, and we study their properties.},
	pages = {525--534},
	booktitle = {Proceedings of the 31st Annual {ACM}/{IEEE} Symposium on Logic in Computer Science},
	publisher = {{ACM}},
	author = {Staton, Sam and Yang, Hongseok and Wood, Frank and Heunen, Chris and Kammar, Ohad},
	urldate = {2018-08-20},
	date = {2016},
	file = {ACM Full Text PDF:/home/supervenom/Zotero/storage/VQJJ5FCL/Staton et al. - 2016 - Semantics for Probabilistic Programming Higher-or.pdf:application/pdf}
}

@inproceedings{borgstrom_lambda-calculus_2016,
	title = {A Lambda-calculus Foundation for Universal Probabilistic Programming},
	abstract = {We develop the operational semantics of an untyped probabilistic λ-calculus with continuous distributions, and both hard and soft constraints,as a foundation for universal probabilistic programming languages such as Church, Anglican, and Venture. Our first contribution is to adapt the classic operational semantics of λ-calculus to a continuous setting via creating a measure space on terms and defining step-indexed approximations. We prove equivalence of big-step and small-step formulations of this distribution-based semantics. To move closer to inference techniques, we also define the sampling-based semantics of a term as a function from a trace of random samples to a value. We show that the distribution induced by integration over the space of traces equals the distribution-based semantics. Our second contribution is to formalize the implementation technique of trace Markov chain Monte Carlo ({MCMC}) for our calculus and to show its correctness. A key step is defining sufficient conditions for the distribution induced by trace {MCMC} to converge to the distribution-based semantics. To the best of our knowledge, this is the first rigorous correctness proof for trace {MCMC} for a higher-order functional language, or for a language with soft constraints.},
	pages = {33--46},
	booktitle = {Proc. of the 21st {ICFP}},
	author = {Borgström, Johannes and Dal Lago, Ugo and Gordon, Andrew D. and Szymczak, Marcin},
	date = {2016},
	keywords = {Lambda-calculus, Machine Learning, {MCMC}, Operational Semantics, Probabilistic Programming}
}

@inproceedings{goodman_church:_2008,
	title = {Church: A Language for Generative Models},
	shorttitle = {Church},
	abstract = {Formal languages for probabilistic modeling enable re-use, modularity, and descriptive clarity, and can foster generic inference techniques. We introduce Church, a universal language for describing stochastic generative processes. Church is based on the Lisp model of lambda calculus, containing a pure Lisp as its deterministic subset. The semantics of Church is defined in terms of evaluation histories and conditional distributions on such histories. Church also includes a novel language construct, the stochastic memoizer, which enables simple description of many complex non-parametric models. We illustrate language features through several examples, including: a generalized Bayes net in which parameters cluster over trials, infinite {PCFGs}, planning by inference, and various non-parametric clustering models. Finally, we show how to implement query on any Church program, exactly and approximately, using Monte Carlo techniques.},
	pages = {220--229},
	booktitle = {Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence},
	publisher = {{AUAI} Press},
	author = {Goodman, Noah D. and Mansinghka, Vikash K. and Roy, Daniel and Bonawitz, Keith and Tenenbaum, Joshua B.},
	date = {2008}
}