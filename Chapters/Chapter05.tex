%************************************************
\chapter{Further Investigations and Future Work}
%************************************************
We have already asserted that studying the randomised strategy $\mathsf{P}_\varepsilon$ in the scope of the full $\lambda$-calculus is hard. More precisely the following problems are conjectured undecidable.
\begin{itemize}
	\item Finding the class of terms $\mathcal{C}\subset\Lambda$ such that for each term $\termone\in\mathcal{C}$, there exists $0<\varepsilon<1$ such that $\explen{\termone}(\varepsilon)<\nsteps{\pslo}$ and $\explen{\termone}(\varepsilon)<\nsteps{\psri}$.
	\item Computing in closed form, for each term $\termone\in\mathcal{C}$, $\explen{\termone}(\termone)$.
\end{itemize}
Thus our investigations should lose some generality. In the previous Chapter we have restricted the set of terms, considering the sub-calculi $\lambda A$ and $\lambda I$. In this Chapter instead we use an experimental approach trying to find a subset of $\mathcal{C}$. In order to check if $\termone\in\mathcal{C}$, we proceed computing $\explen{\termone}(\epsilon)$ and then testing if the minimum $\mu$ is such that $0<\mu<1$. How can we determine $\explen{\termone}(\epsilon)$? Since the problem is undecidable we provide a pseudo-algorithm, that intuitively builds trees like those we have presented in the previous Chapter. Those trees were finite although the presence of infinite reduction sequences because of a \emph{blocking procedure}. When a term rewrites to itself, a self-loop is added and no child is added. This method clearly is not complete. For example we would not be able to represent in this way terms like $\termone = (\lambda x.\lambda y.y)\bm{\Delta_4}$. Instead we are able to tackle the $\bm{\Omega}$ combinator.
\section{The Tool}
To test a large number of terms, proceeding pencil and paper would not be feasible. Thus we developed an automatic tool performing all the computations. The tool is composed of different components.
\begin{itemize}
	\item An interpreter of the $\lambda$-calculus with both $\pslo$ and $\psri$ strategies. This component implements a parser, $\alpha$-conversion and the actual evaluator implementing $\beta$-reduction.
	\item A component implementing the pseudo-algorithm building blocked trees from a term $\termone$ and then computing $\explen{\termone}(\varepsilon)$.
	\item An analyser of $\explen{\termone}(\varepsilon)$, that plots it and computes its derivative and its minimum. 
\end{itemize}
There is the great difference between the first two components, dealing mainly with symbolic manipulation of terms and structures and the last one dealing with computer algebra, numerical analysis and data visualisation. For this reason first two components were implemented in \texttt{Haskell} while the last one in \texttt{Python}. In fact \texttt{Haskell} is perfect to manage inductive data structures such as $\lambda$-terms while \texttt{Python} has a rich project, \textsf{Scipy}, comprehending good libraries for computer algebra (\textsf{SymPy}), numerical analysis (\textsf{SciPy} and \textsf{NumPy}) and data visualisation (\textsf{Matplotlib}). Communication between the two languages is achieved through a common syntax for symbolic expressions.
\subsection{Main Data Types and Functions}
According to the grammar defining the $\lambda$-calculus, terms are defined as:
$$
\texttt{data Term = Var String | Abs Name Term | App Term Term}
$$
Substitution is easily defined thanks to pattern matching:
\begin{align*}
&\texttt{subst :: Term -> String -> Term -> Term}\\
&\texttt{subst (Var x) y z}\\
&\qquad\texttt{|x == y = z}\\
&\qquad\texttt{|otherwise = (Var x)}\\
&\texttt{subst (Abs y x) z w = (Abs y (subst x z w))}\\
&\texttt{subst (App x y) z w = (App (subst x z w) (subst y z w))}
\end{align*}
Please note that this substitution is \emph{not} capture avoiding. Terms should be $\alpha$-converted first. $\beta$-reduction is defined as usual:
\begin{align*}
&\texttt{beta :: Term -> Term}\\
&\texttt{beta (App (Abs y x) z) = subst x y z}
\end{align*}
Since the reduction process depends on the reduction strategy, \texttt{reduce} is a higher-order function. A heuristics halts the reduction process in the case a term reduces to itself:
\begin{align*}
&\texttt{reduce :: (Term -> Term) -> Term -> Term}\\
&\texttt{reduce eval term}\\
&\qquad\texttt{|(eval term) == term = term}\\
&\qquad\texttt{|otherwise = reduce eval (eval term)}
\end{align*}
Leftmost-outermost strategy is implemented in the following way (rightmost-innermost is symmetrical):
\begin{align*}
&\texttt{evalLO :: Term -> Term}\\
&\texttt{evalLO (Var x) = Var x}\\
&\texttt{evalLO (Abs y x) = Abs y (evalLO x)}\\
&\texttt{evalLO (App x y)}\\
&\qquad\texttt{|(isRedex (App x y)) = beta (App x y)}\\
&\qquad\texttt{|(hasRedexes x) = (App (evalLO x) y)}\\
&\qquad\texttt{|(hasRedexes y) = (App x (evalLO y))}\\
&\qquad\texttt{|otherwise = (App x y)}
\end{align*}