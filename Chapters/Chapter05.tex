%************************************************
\chapter{Further Investigations and Future Work}
%************************************************
We have already asserted that studying the randomised strategy $\mathsf{P}_\varepsilon$ in the scope of the full $\lambda$-calculus is hard. More precisely the following problems are conjectured to be very hard.
\begin{itemize}
	\item Finding a class of terms $\mathcal{C}\subset\Lambda$ such that for each term $\termone\in\mathcal{C}$, there exists $0<\varepsilon<1$ such that $\explen{\termone}(\varepsilon)<\nsteps{\pslo}(\termone)$ and $\explen{\termone}(\varepsilon)<\nsteps{\psri}(\termone)$.
	\item Computing in closed form, for each term $\termone\in\mathcal{C}$, $\explen{\termone}(\termone)$.
\end{itemize}
Thus our investigations should lose some generality. In the previous Chapter we have restricted the set of terms, considering the sub-calculi $\lambda A$ and $\lambda I$. In this Chapter, instead, we use an experimental approach trying to find a class $\mathcal{C}$ as above. In order to check if $\termone\in\mathcal{C}$, we proceed computing $\explen{\termone}(\epsilon)$ and then testing if the minimum $\mu$ is such that $0<\mu<1$. How can we determine $\explen{\termone}(\epsilon)$? Since the problem is undecidable we provide a pseudo-algorithm, that intuitively builds trees like those we have presented in the previous Chapter. Because of the presence of infinite reduction paths, a heuristics has to be adopted in order to have a finite representation. We restricted to a particular, yet meaningful case: terms that rewrite to themselves. This way, during the construction of the tree, when a term rewrites to itself, a self-loop is added and no child is added. This method clearly is not complete. For example we would not be able to represent finitely terms like $\termone = (\lambda x.\lambda y.y)\bm{\Delta_4}$. Instead we are able to tackle the $\bm{\Omega}$ combinator.
\section{The Tool}
To test a large number of terms, the use of pencil and paper would not be feasible. Thus we developed an automatic tool performing all the computations. The tool is composed of three different components.
\begin{itemize}
	\item An interpreter of the $\lambda$-calculus with both $\pslo$ and $\psri$ strategies. This component implements a parser, $\alpha$-conversion and the actual evaluator implementing $\beta$-reduction.
	\item A component implementing the pseudo-algorithm building the tree from a term $\termone$ and then computing $\explen{\termone}(\varepsilon)$.
	\item An analyser of $\explen{\termone}(\varepsilon)$, that plots it and computes its derivative and its minimum. 
\end{itemize}
There is the great difference between the first two components, dealing mainly with symbolic manipulation of terms and structures and the last one dealing with computer algebra, numerical analysis and data visualisation. For this reason first two components were implemented in \texttt{Haskell} while the last one in \texttt{Python}. In fact \texttt{Haskell} is perfect to manage inductive data structures such as $\lambda$-terms while \texttt{Python} provides a library, \textsf{Scipy}, comprehending libraries for computer algebra (\textsf{SymPy}), numerical analysis (\textsf{SciPy} and \textsf{NumPy}) and data visualisation (\textsf{Matplotlib}). Communication between the two languages is achieved through a common syntax for symbolic expressions.
\subsection{Main Data Types and Functions}
According to the grammar defining the $\lambda$-calculus, terms are defined as:
$$
\texttt{data Term = Var String | Abs Name Term | App Term Term}
$$
Substitution is easily defined thanks to pattern matching:
\begin{align*}
&\texttt{subst :: Term -> String -> Term -> Term}\\
&\texttt{subst (Var x) y z}\\
&\qquad\texttt{|x == y = z}\\
&\qquad\texttt{|otherwise = (Var x)}\\
&\texttt{subst (Abs y x) z w = (Abs y (subst x z w))}\\
&\texttt{subst (App x y) z w = (App (subst x z w) (subst y z w))}
\end{align*}
Please note that this substitution is \emph{not} capture avoiding. Terms should be $\alpha$-converted first. $\beta$-reduction is defined as usual:
\begin{align*}
&\texttt{beta :: Term -> Term}\\
&\texttt{beta (App (Abs y x) z) = subst x y z}
\end{align*}
Since the reduction process depends on the reduction strategy, \texttt{reduce} is a higher-order function. A heuristics halts the reduction process in the case a term reduces to itself:
\begin{align*}
&\texttt{reduce :: (Term -> Term) -> Term -> Term}\\
&\texttt{reduce eval term}\\
&\qquad\texttt{|(eval term) == term = term}\\
&\qquad\texttt{|otherwise = reduce eval (eval term)}
\end{align*}
Leftmost-outermost strategy reduces always the leftmost redex, if any, and is implemented in the following way (rightmost-innermost is symmetrical):
\begin{align*}
&\texttt{evalLO :: Term -> Term}\\
&\texttt{evalLO (Var x) = Var x}\\
&\texttt{evalLO (Abs y x) = Abs y (evalLO x)}\\
&\texttt{evalLO (App x y)}\\
&\qquad\texttt{|(isRedex (App x y)) = beta (App x y)}\\
&\qquad\texttt{|(hasRedexes x) = (App (evalLO x) y)}\\
&\qquad\texttt{|(hasRedexes y) = (App x (evalLO y))}\\
&\qquad\texttt{|otherwise = (App x y)}
\end{align*}
The tree (eventually with self-loops) for each term is represented by the following data type:
\begin{align*}
	\texttt{data PTree = }&\texttt{PLeaf | NodeOne PTree |}\\
	&\texttt{NodeOneCycle PTree | NodeTwo PTree PTree}
\end{align*}
The tree is built simply considering the reduction of the term $\termone$ according to $\pslo$ and $\psri$ strategy. A \texttt{PLeaf} is created if the term is in normal form, a \texttt{NodeOne} if $\pslo$-reduct and $\psri$-reduct coincide, a \texttt{NodeTwo} if they are distinct and a \texttt{NodeCycle} if the $\psri$-reduct rewrites to itself.
\begin{align*}
&\texttt{buildPTree :: Term -> PTree}\\
&\texttt{buildPTree term}\\
&\qquad\texttt{|not (hasRedexes term) = PLeaf}\\
&\qquad\texttt{|(evalLO term) == (evalRI term)}\\
&\quad\qquad\texttt{= NodeOne (buildPTree (evalLO term))}\\
&\qquad\texttt{|(evalRI term) == term}\\
&\qquad\quad\texttt{= NodeOneCycle (buildPTree (evalLO term))}\\
&\qquad\texttt{|otherwise = NodeTwo (buildPTree (evalLO term))}\\
&\qquad\quad\texttt{(buildPTree (evalRI term))}
\end{align*}
Once one has built the tree for a term $\termone$, it is easy to compute $\explen{\termone}$. If $\termone\redlo\termtwo$ and $\termone\redri\termthree$, then
$$
\explen{\termone}=1+\varepsilon\cdot\explen{\termtwo}+(1-\varepsilon)\cdot\explen{\termthree}.
$$
We have already proved in Example \ref{example:omega} that if $\termone\redri\termone$ and $\explen{\termtwo}(\varepsilon)=0$, then $\explen{\termone}(\varepsilon)=\frac{1}{\varepsilon}$. The construction can be gereralised to arbitrary values of $\explen{\termtwo}$, yielding $\explen{\termone}(\varepsilon)=\frac{1}{\varepsilon}+\explen{\termtwo}$. Clearly if $\termone$ is in normal form, then $\explen{\termone}=0$. All this ingredients allow to compute $\explen{\termone}$ inductively on the structure of the tree. This is a pseudo-algorithm in that it is not assured to terminate. Diverging terms different from $\bm{\Omega}$ in fact yield to non-terminating computations. We report the code in \texttt{pseudo-Haskell}.
\begin{align*}
&\texttt{bExpr :: PTree -> Expression}\\
&\texttt{bExpr PLeaf = 0}\\
&\texttt{bExpr (NodeOne t) = 1 + (bExpr t)}\\
&\texttt{bExpr (NodeOneCycle t) = 1/}\varepsilon\texttt{ + (bExpr t)}\\
&\texttt{bExpr (NodeTwo t1 t2) = 1 + }\varepsilon\texttt{*(bExpr t1) + (1-}\varepsilon\texttt{)*(bExpr t2)}
\end{align*}
\section{Experimental Results}
Once the tool is set, it is easy to test different terms. Our goal is to try to find a subset of the class $\mathcal{C}$ of terms for which strategy $\mathsf{P}_\varepsilon$, $\varepsilon\not\in\{0,1\}$, is more convenient than $\pslo$ and $\psri$. We already know that $\mathcal{C}\subseteq\Lambda\setminus(\Lambda_A\cup\Lambda_I)$. First we give an answer to the following trivial question: is $\mathcal{C}$ a proper subset of $\Lambda\setminus(\Lambda_A\cup\Lambda_I)$?
\begin{proposition}\label{prop:strict}
	$\mathcal{C}\subset\Lambda\setminus(\Lambda_A\cup\Lambda_I)$.
\end{proposition}
\begin{proof}
	We provide a family of terms $\termone_n\in\Lambda\setminus(\Lambda_A\cup\Lambda_I)$ such that $\nsteps{\pslo}(\termone)=\explen{\termone}(1)<\explen{\termone}(\varepsilon)$ if $0<\varepsilon<1$.
	$$
	\termone_n=\termthree_n((\lambda y.z)\bm{\Omega})
	$$
	where:
	$$
	\termthree_n = C_n((\lambda x.x)y)\qquad
	C_n = \lambda  x.\underbrace{xx\cdots x}_{n\text{ times}}
	$$
	It is then easy to compute the average number of steps to normal form that is
	$$
	\explen{\termone_n}(\varepsilon)=\frac{n+2}{\varepsilon}.
	$$ 
	The function $\explen{\termone_n}$ is strictly decreasing.\\
	This proves the claim.
\end{proof}
We have at this point examples of terms in and out of $\mathcal{C}$. What differences there are between them? Can they be spotted \emph{algorithmically} with \emph{low} complexity? Some considerations can be done about the different phenomena that arise in the reduction of a $\lambda$-term: namely \emph{copy} and \emph{cancellation}. In general we want that copy is done after having reduced the argument to normal form, while cancellation should anticipated as much as possible. We define in an informal manner a set of operations $\mathcal{O}$ performed by $\lambda$-terms. We attach an operation $\mathsf{O}\in\mathcal{O}$ to each term formalised with the map $\mathsf{Op}:\Lambda\rightarrow\mathcal{O}$.
\begin{definition} Let $n\geq 0$, then $\mathcal{O}=\{\textsf{CP},\textsf{CA},\textsf{W}_n\}$ where:
	\begin{itemize}
		\item $\textsf{CP}$ is a copy operation exemplified by a term $\termone=\lambda x.\termtwo$ where $x$ is free more than once in $\termtwo$. We write $\textsf{CP(O)}$ if $\mathsf{O}$ is the operation copied, i.e. if it is the case $\termone\termthree$ with $\mathsf{Op}(\termthree)=\mathsf{O}$.
		\item $\textsf{CA}$ is a cancellation operation exemplified by a term $\termone=\lambda x.\termtwo$ where $x$ is not free in $\termtwo$. We write $\textsf{CA(O)}$ if $\mathsf{O}$ is the operation cancelled, i.e. if it is the case $\termone\termthree$ with $\mathsf{Op}(\termthree)=\mathsf{O}$.
		\item $\mathsf{W_n}$ is strategy independent reduction work that takes $n$ steps to reach normal form. It is exemplified by a term $\underbrace{\textbf{II...I}}_{n+1\text{ times}}$.
	\end{itemize}
\end{definition}
What is interesting is the order in which these operations are executed. Copying some work before it was executed brings to multiplication of work. In the same way doing some reduction work that later will be cancelled is useless. Let us consider the term $\termone_n$ provided in the Proof of Proposition~\ref{prop:strict}. In Table~\ref{table:op1} the different operations are related to the different subterms of $\termone_n$. The order is left-to-right in the sense that $\textsf{O}_1\prec\mathsf{O}_2$ if the corresponding subterms are ordered that way in the linear representation of the term. We note that both leftmost and rightmost operations are not the best choice. In fact leftmost we have a copy before some work and rightmost we do some useless work.
\begin{table}
\begin{center}
\begin{tabular}{|c|c|c|c|}
	\hline 
	$ \textsf{CP} $ & $ \textsf{W}_1 $ & $ \textsf{CA} $ & $ \textsf{W}_\infty $\tabularnewline
	\hline 
	$C_n$ & $(\lambda x.x)y$ & $\lambda y.z$ & $\bm{\Omega}$\tabularnewline
	\hline 
\end{tabular}
\end{center}
\caption{Different operations in term $\termone_n$ from Proposition~\ref{prop:strict}}
\label{table:op1}
\end{table}